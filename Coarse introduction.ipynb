{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Veri_Seti3_201701_In = pd.read_csv('./Dataset 3/Dataset 3_201701_In.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALLER_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>ID</th>\n",
       "      <th>CITY_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100144895</td>\n",
       "      <td>02-01-2017 12:52</td>\n",
       "      <td>568</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100144895</td>\n",
       "      <td>02-01-2017 20:40</td>\n",
       "      <td>568</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100144895</td>\n",
       "      <td>02-01-2017 21:41</td>\n",
       "      <td>568</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100144895</td>\n",
       "      <td>03-01-2017 14:57</td>\n",
       "      <td>828</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100144895</td>\n",
       "      <td>05-01-2017 10:01</td>\n",
       "      <td>568</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CALLER_ID         TIMESTAMP   ID  CITY_ID\n",
       "0  1100144895  02-01-2017 12:52  568        7\n",
       "1  1100144895  02-01-2017 20:40  568        7\n",
       "2  1100144895  02-01-2017 21:41  568        7\n",
       "3  1100144895  03-01-2017 14:57  828        7\n",
       "4  1100144895  05-01-2017 10:01  568        7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Veri_Seti3_201701_In, index = [0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from January dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JanuaryIn = np.asarray(Veri_Seti3_201701_In)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length, width = JanuaryIn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 998625 calls recorded in this dataset\n"
     ]
    }
   ],
   "source": [
    "print ('there are {} calls recorded in this dataset'.format(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamp = pd.to_datetime(JanuaryIn[0:length,1], format=\"%d-%m-%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = np.asarray(timestamp.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract called ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callerID = JanuaryIn[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callerID = callerID.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = []\n",
    "for i in callerID:\n",
    "    prefix.append(i[0])\n",
    "\n",
    "prefix = np.asarray(prefix)\n",
    "prefix = prefix.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 758728 refugee calls in this dataset\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(prefix, return_counts=True)\n",
    "print ('there are {} refugee calls in this dataset'.format(counts[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract city ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cityID = JanuaryIn[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_analyse = np.unique(callerID[prefix==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = callerID[timestamp.hour >= 18]\n",
    "h2 = callerID[timestamp.hour <= 7]\n",
    "h = np.append(h1,h2)\n",
    "overlap = np.intersect1d(h,to_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evening_location = {}\n",
    "for i in overlap:\n",
    "    evening_location[str(i)] = {\n",
    "        'cities':[],\n",
    "        'dates':[]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "#bottleneck - fix this\n",
    "bar = progressbar.ProgressBar(maxval=len(overlap), \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "counter = 0\n",
    "for i in overlap:\n",
    "    location =  np.where(callerID == i)\n",
    "    cities = cityID[location[0]]\n",
    "    evening_location[i]['cities'] = cities\n",
    "    dates = date[location[0]]\n",
    "    evening_location[i]['dates'] = dates\n",
    "    counter += 1\n",
    "    #if counter%100 == 0:\n",
    "    #    print (counter)\n",
    "    bar.update(counter)\n",
    "#    sleep(0.1)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save evening_locations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"evening_location.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(evening_location, fp, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"evening_location.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    evening_location = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile = [] #find the refugees who spend their time in more that one city in the evening over the month\n",
    "for i in evening_location:\n",
    "    unique, counts = np.unique(evening_location[i]['cities'], return_counts=True)\n",
    "    if len(unique) > 1:\n",
    "        mobile.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1651 callers out ot 50,000 refugees who moved cities\n"
     ]
    }
   ],
   "source": [
    "print ('there are {} callers out ot 50,000 refugees who moved cities'.format(len(mobile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated cities moved between (i.e. were in 'residence' for more that 4 nights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in mobile:\n",
    "    moved = [evening_location[i]['cities'][0]]\n",
    "    date_moved = evening_location[i]['dates'][0]\n",
    "    for j in range(1, len(evening_location[i]['cities'])):\n",
    "        diff = np.timedelta64(evening_location[i]['dates'][j-1]-date_moved)\n",
    "        diff = int(diff.astype('timedelta64[D]') / np.timedelta64(1, 'D'))\n",
    "        if diff >=4 and evening_location[i]['cities'][j-1] != moved[-1]:\n",
    "            moved.append(evening_location[i]['cities'][j-1])\n",
    "            date_moved = evening_location[i]['dates'][j]\n",
    "    evening_location[i]['moved'] = moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_mobility = []\n",
    "medium_mobility = []\n",
    "high_mobility = []\n",
    "for i in mobile:\n",
    "    if len(evening_location[i]['moved']) <=2:\n",
    "        low_mobility.append(i)\n",
    "    elif 2 < len(evening_location[i]['moved']) <=5:\n",
    "        medium_mobility.append(i)\n",
    "    else:\n",
    "        high_mobility.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 835 refugees classed as low mobility\n",
      "There are 816 refugees classed as medium mobility\n",
      "There are 0 refugees classed as high mobility\n"
     ]
    }
   ],
   "source": [
    "print ('There are {} refugees classed as low mobility'.format(len(low_mobility)))\n",
    "print ('There are {} refugees classed as medium mobility'.format(len(medium_mobility)))\n",
    "print ('There are {} refugees classed as high mobility'.format(len(high_mobility)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis for cities from which refugees leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_cities = np.zeros(81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in mobile:\n",
    "    moved = evening_location[i]['moved']\n",
    "    unique, counts = np.unique(moved, return_counts=True)\n",
    "    for j in range(len(unique)):\n",
    "        # think about criterion for repeated city!!!\n",
    "        if counts[j] == 1:\n",
    "            bad_cities[unique[j]-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146.,  31.,  20.,   2.,   8., 132.,  77.,   4.,  28.,  30.,   8.,\n",
       "         2.,   5.,  23.,  10., 107.,  14.,  12.,   6.,  17.,  18.,  15.,\n",
       "        11.,   5.,   6.,  26., 161.,   7.,   2.,   1.,  83.,  22., 115.,\n",
       "       467., 108.,   6.,  11.,  16.,  15.,   9., 179.,  55.,   9.,   7.,\n",
       "        47.,  34.,  14.,  21.,   3.,   6.,  12.,   6.,   2.,  48.,   9.,\n",
       "         3.,   3.,   6.,  59.,   5.,   9.,   2.,  80.,   4.,  11.,   3.,\n",
       "        10.,  12.,   0.,   8.,  14.,   7.,   6.,   1.,   1.,   1.,  47.,\n",
       "        11.,  34.,  41.,  19.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_mapping = pd.read_csv('./Mapping IDs/Dataset3_City_Mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_cities_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_mapping = np.asarray(city_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(city_mapping)):\n",
    "    bad_cities_names[city_mapping[i,1]] = bad_cities[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst cities for refugees moving out of are:\n",
      "HATAY\n",
      "SANLIURFA\n",
      "GAZIANTEP\n",
      "MERSIN\n",
      "KOCAELI\n",
      "ANTALYA\n",
      "ANKARA\n",
      "ADANA\n",
      "TEKIRDAG\n",
      "ISTANBUL\n",
      "BURSA\n",
      "KONYA\n",
      "IZMIR\n"
     ]
    }
   ],
   "source": [
    "print ('The worst cities for refugees moving out of are:')\n",
    "for i in bad_cities_names:\n",
    "    if bad_cities_names[i] >=50:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 1), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 2), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 3), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 5), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 6), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 7), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 8), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 9), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 11), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 12), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 13), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 14), datetime.date(2017, 1, 15), datetime.date(2017, 1, 15), datetime.date(2017, 1, 15), datetime.date(2017, 1, 15), datetime.date(2017, 1, 15), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16), datetime.date(2017, 1, 16)]\n"
     ]
    }
   ],
   "source": [
    "print ([x for x,_ in sorted(zip(evening_location[mobile[0]]['dates'],evening_location[mobile[0]]['cities']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare against non-refugee population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_to_analyse = np.unique(callerID[prefix==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_h1 = callerID[timestamp.hour >= 18]\n",
    "non_h2 = callerID[timestamp.hour <= 7]\n",
    "non_h = np.append(non_h1,non_h2)\n",
    "non_overlap = np.intersect1d(non_h,non_to_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_evening_location = {}\n",
    "for i in non_overlap:\n",
    "    non_evening_location[str(i)] = {\n",
    "        'cities':[],\n",
    "        'dates':[]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##bottleneck - could parallelise better\n",
    "for i in non_overlap:\n",
    "    location =  np.where(callerID == i)\n",
    "    cities = cityID[location[0]]\n",
    "    non_evening_location[i]['cities'] = cities\n",
    "    dates = date[location[0]]\n",
    "    non_evening_location[i]['dates'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"non_evening_location.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(non_evening_location, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"non_evening_location.txt\", \"rb\") as fp:   # Unpickling\n",
    "    non_evening_location = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_mobile = [] #find the refugees who spend their time in more that one city in the evening over the month\n",
    "for i in non_evening_location:\n",
    "    unique, counts = np.unique(non_evening_location[i]['cities'], return_counts=True)\n",
    "    if len(unique) > 1:\n",
    "        non_mobile.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('there are {} callers out ot 50,000 non-refugees who moved cities'.format(len(non_mobile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('there are {} times as many refugees who moved cities as non-refugees'.format(\n",
    "    round(float(len(mobile))/float(len(non_mobile)),2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
